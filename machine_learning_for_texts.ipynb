{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a84dd53c",
   "metadata": {},
   "source": [
    "# **Тональность текстовых сообщений**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "081ca5e3",
   "metadata": {},
   "source": [
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. \n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Необходимо построить модель со значением метрики качества *F1* не меньше 0.75. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeca6bc-9401-45bb-a316-51a54f803924",
   "metadata": {},
   "source": [
    "# Цель проекта"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4746b4cf",
   "metadata": {},
   "source": [
    "**Главной задачей** данного проекта стала классификация комментариев изменений в описании товаров интернет-магазина «Викишоп», для отслеживания токсичных комментариев для своевременной отправки на модерацию. В ходе проекта будет подобрана лучшая модель-классификатор с оптимальными гиперпараметрами, согласно поставленной задаче."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c13ae513-6b14-4cc2-b976-5d42f385556c",
   "metadata": {},
   "source": [
    "# Предоставленные заказчиком данные"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a126bc9",
   "metadata": {},
   "source": [
    "Заказчик предоставил исходные данные, которые содержат в себе следующие признаки:\n",
    "- text - необработанный текст комментариев\n",
    "- toxic - является ли комментарий токсичным (целевой признак)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70901188",
   "metadata": {},
   "source": [
    "## Подготовка"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290bb01a",
   "metadata": {},
   "source": [
    "Для начала следует импортировать все необходимые библиотеки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "785e89a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "from tqdm import tqdm\n",
    "from tqdm import notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1a48d5",
   "metadata": {},
   "source": [
    "Далее я установлю то, что требует дополнительных расширений при установке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37ef9380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package_name\n",
      "  Downloading package_name-0.1.tar.gz (782 bytes)\n",
      "Building wheels for collected packages: package-name\n",
      "  Building wheel for package-name (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for package-name: filename=package_name-0.1-py3-none-any.whl size=1267 sha256=d1905ef674c99171922c11ebd559965f62f6dacacaa39ba25020a16c858424e9\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/67/e6/c3/cbfcab244d830378592564f5e46da23a8aad979c4a958b401a\n",
      "Successfully built package-name\n",
      "Installing collected packages: package-name\n",
      "Successfully installed package-name-0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install package_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9800b0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "en-core-web-sm 3.2.0 requires spacy<3.3.0,>=3.2.0, but you have spacy 3.7.2 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -Uq spacy\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "690a5f17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.0\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.0/en_core_web_sm-3.7.0-py3-none-any.whl (12.8 MB)\n",
      "\u001b[K     |████████████████████████████████| 12.8 MB 1.3 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.9/site-packages (from en-core-web-sm==3.7.0) (3.7.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (21.3)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.8)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.2.1)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.61.2)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.8.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.3.0)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.8)\n",
      "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.25.1)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.0.6)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (49.6.0.post20210108)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.21.1)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (5.2.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.4)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.10.1)\n",
      "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.3.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.7)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.0.3)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.9/site-packages (from spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (3.0.12)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.9/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.3.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2022.6.15)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (4.0.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.9/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (1.26.6)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.1.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.9/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.7.8)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.9/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (8.1.3)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.9/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.9/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->en-core-web-sm==3.7.0) (2.1.1)\n",
      "Installing collected packages: en-core-web-sm\n",
      "  Attempting uninstall: en-core-web-sm\n",
      "    Found existing installation: en-core-web-sm 3.2.0\n",
      "    Uninstalling en-core-web-sm-3.2.0:\n",
      "      Successfully uninstalled en-core-web-sm-3.2.0\n",
      "Successfully installed en-core-web-sm-3.7.0\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n"
     ]
    }
   ],
   "source": [
    "!python3 -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3595d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import doc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c1f86ee",
   "metadata": {},
   "source": [
    "Далее следует загрузить файл таким образом, чтобы он был корректно загружен и на ядро Яндекс Практикума и в моем локальном юпитере."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d4fb7b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_1\n"
     ]
    }
   ],
   "source": [
    "pth1 = '/datasets/toxic_comments.csv'\n",
    "pth2 = '/Users/anastasiaklubkova/Downloads/toxic_comments (1).csv'\n",
    "\n",
    "if os.path.exists(pth1):\n",
    "    data_1 = pd.read_csv(pth1)\n",
    "    print('data_1')\n",
    "elif os.path.exists(pth2):\n",
    "    data_2 = pd.read_csv(pth2)\n",
    "    print('data_2')\n",
    "else:\n",
    "    print('Something is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a583bd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159292 entries, 0 to 159291\n",
      "Data columns (total 3 columns):\n",
      " #   Column      Non-Null Count   Dtype \n",
      "---  ------      --------------   ----- \n",
      " 0   Unnamed: 0  159292 non-null  int64 \n",
      " 1   text        159292 non-null  object\n",
      " 2   toxic       159292 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 3.6+ MB\n"
     ]
    }
   ],
   "source": [
    "data_1.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ec54e0",
   "metadata": {},
   "source": [
    "На данном этапе пропусков не обнаружено (согласно info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "530e78d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  toxic\n",
       "0           0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1           1  D'aww! He matches this background colour I'm s...      0\n",
       "2           2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3           3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4           4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1569131",
   "metadata": {},
   "source": [
    "Данный столбец не является информативным, поэтому его стоит удалить для избежания дальнейшей интерпретации как признака"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32c32eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['text', 'toxic'], dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data_1.drop(columns = ['Unnamed: 0'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6352c077",
   "metadata": {},
   "source": [
    "Стоит проверить на наличие дубликатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c092c592",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bec98",
   "metadata": {},
   "source": [
    "Дубликатов не обнаружено."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9bbdbcca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/jovyan/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceabd329",
   "metadata": {},
   "source": [
    "На данном этапе я приступаю к очистке текста посредством поиска стоп-слов, а также посредством регулярных выражений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "158d3a42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_text(text):\n",
    "    clear_text = re.sub(r'[^a-zA-Z]+', ' ', text).lower()\n",
    "    return \" \".join(clear_text.split())\n",
    "    \n",
    "\n",
    "def clean_stop_words(text, stopwords):\n",
    "    text = [word for word in text.split() if word not in stopwords]\n",
    "    return \" \".join(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0f1cf82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'in', 'can', 'then', 'don', 'needn', 'myself', 'me', 'same', 'both', 'should', 'so', 'few', 'to', 'through', 'at', \"wouldn't\", 'wouldn', 'over', 've', 'having', 'them', 'which', 'doing', \"that'll\", 'themselves', 'my', 'this', 'that', 'and', 'again', 'her', 'or', 'itself', 'above', 'hadn', 'mightn', 'do', 'once', 'yours', 'from', 'most', 'he', 'but', 'ours', \"hasn't\", \"shan't\", 'his', 'were', 'before', 'all', 'couldn', 'won', 'why', 'doesn', 'shouldn', 't', 'ain', 'where', 'between', 'each', \"needn't\", 'himself', 'have', 'ma', 'him', 'while', 'being', 'hasn', 'up', \"isn't\", 'by', 'our', 'an', 'hers', 'very', 'off', 'with', 'after', \"should've\", 'm', 'than', \"haven't\", \"she's\", 'below', 'aren', 'a', 'your', 'not', 'haven', 'wasn', 'you', 'just', 'herself', \"mustn't\", \"you're\", 'own', 'didn', 'the', 'some', \"you'd\", 'of', 'isn', 'other', 's', 'too', 'it', 'if', 'for', \"couldn't\", 'here', 'weren', 'o', 'what', 'she', 'who', 'on', \"wasn't\", \"weren't\", 're', 'am', 'be', 'out', \"hadn't\", \"doesn't\", 'how', 'now', 'because', 'd', 'their', 'more', \"mightn't\", \"don't\", 'y', 'does', 'further', 'was', 'did', 'against', 'll', \"didn't\", 'been', \"you'll\", 'mustn', 'will', 'we', \"won't\", 'shan', 'its', 'those', 'ourselves', 'into', 'as', 'i', 'under', 'these', \"it's\", 'yourselves', 'yourself', 'has', 'only', 'about', \"you've\", 'there', 'any', 'nor', \"aren't\", 'such', 'during', 'until', \"shouldn't\", 'they', 'are', 'is', 'down', 'when', 'had', 'no', 'theirs', 'whom'}\n"
     ]
    }
   ],
   "source": [
    "# загрузим список стоп-слов\n",
    "stopwords = set(nltk_stopwords.words('english'))\n",
    "print(np.array(stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbaac48",
   "metadata": {},
   "source": [
    "Далее следует протестировать функции очистки текста."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d58f477d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello 128.6. They do single me out. Put the freaking 0.8 steals average back. I know the rules, if you can't argue against what I write, then I keep it. You can't stop me unless you have legitimiate argument against why they are wrong. Look at my RECENT POST for the STEVE NASH when I posted all that info under strengths and weaknesses and the MVP 2006 and THEN and argue why some of it should not be on??? I am just too superior. I can take down and beat up all your arguments for it. WHY?? Because what I post is REAL! I KEEP IT REAL. FRAUD NEVER WINS 128.6. IT NEVER DOES.  hganesan\n",
      "=======================================\n",
      "hello single put freaking steals average back know rules argue write keep stop unless legitimiate argument wrong look recent post steve nash posted info strengths weaknesses mvp argue superior take beat arguments post real keep real fraud never wins never hganesan\n"
     ]
    }
   ],
   "source": [
    "text = data['text'][np.random.randint(data.shape[0])]\n",
    "print(text)\n",
    "print('=======================================')\n",
    "print(clean_stop_words((clear_text(text)), stopwords))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cd1d853",
   "metadata": {},
   "source": [
    "Функции отработали успешно, значит их можно применить к исходным данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7ae10e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Обработка текстов заняла: 6.17 секунд\n"
     ]
    }
   ],
   "source": [
    "start_clean = time()\n",
    "\n",
    "data['text_clear'] = data['text'].apply(lambda x: clean_stop_words(clear_text(str(x)), stopwords))\n",
    "\n",
    "print('Обработка текстов заняла: '+str(round(time() - start_clean, 2))+' секунд')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38eb8755",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         explanation edits made username hardcore metal...\n",
       "1         aww matches background colour seemingly stuck ...\n",
       "2         hey man really trying edit war guy constantly ...\n",
       "3         make real suggestions improvement wondered sec...\n",
       "4                             sir hero chance remember page\n",
       "                                ...                        \n",
       "159287    second time asking view completely contradicts...\n",
       "159288                 ashamed horrible thing put talk page\n",
       "159289    spitzer umm theres actual article prostitution...\n",
       "159290    looks like actually put speedy first version d...\n",
       "159291    really think understand came idea bad right aw...\n",
       "Name: text_clear, Length: 159292, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['text_clear']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1346a39",
   "metadata": {},
   "source": [
    "Чтобы избежать утечки, следует удалить первоначальный текст комментариев, сформировав новый датасет"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "40d320b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['toxic', 'text_clear'], dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(columns = ['text'])\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d537f9c",
   "metadata": {},
   "source": [
    "На следуеющем этапе будет совершена лемматизация признака - комментариев для возможности дальнейшего машинного обучения с помощью библиотеки spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "898a01b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a734ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(doc):\n",
    "    doc = nlp(doc)\n",
    "    return \" \".join([token.lemma_ for token in doc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1fc445c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'explanation edit make username hardcore metallica fan revert vandalism closure gas vote new york dolls fac please remove template talk page since retire'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(data['text_clear'].iloc[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f6aca0c",
   "metadata": {},
   "source": [
    "Тестирование функции лемматизации показало, что она работает, значит ее можно применить ко всему датасету"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b62a6337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12min 5s, sys: 1.12 s, total: 12min 6s\n",
      "Wall time: 12min 6s\n"
     ]
    }
   ],
   "source": [
    "%time data['lemm'] = data['text_clear'].apply(lemmatize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cc22620a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "      <th>text_clear</th>\n",
       "      <th>lemm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>explanation edits made username hardcore metal...</td>\n",
       "      <td>explanation edit make username hardcore metall...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>aww matches background colour seemingly stuck ...</td>\n",
       "      <td>aww match background colour seemingly stuck th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>hey man really trying edit war guy constantly ...</td>\n",
       "      <td>hey man really try edit war guy constantly rem...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>make real suggestions improvement wondered sec...</td>\n",
       "      <td>make real suggestion improvement wonder sectio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "      <td>sir hero chance remember page</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   toxic                                         text_clear  \\\n",
       "0      0  explanation edits made username hardcore metal...   \n",
       "1      0  aww matches background colour seemingly stuck ...   \n",
       "2      0  hey man really trying edit war guy constantly ...   \n",
       "3      0  make real suggestions improvement wondered sec...   \n",
       "4      0                      sir hero chance remember page   \n",
       "\n",
       "                                                lemm  \n",
       "0  explanation edit make username hardcore metall...  \n",
       "1  aww match background colour seemingly stuck th...  \n",
       "2  hey man really try edit war guy constantly rem...  \n",
       "3  make real suggestion improvement wonder sectio...  \n",
       "4                      sir hero chance remember page  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "55f9d90d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "toxic         0\n",
       "text_clear    0\n",
       "lemm          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf063e8c",
   "metadata": {},
   "source": [
    "## Обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0a7243",
   "metadata": {},
   "source": [
    "Для избежания утечки следует также удалить и очищенный текст комментариев, оставив как признак леммы слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5c48d9ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = ['text_clear'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150c3911",
   "metadata": {},
   "source": [
    "Далее следует разделить данные на обучающую и тестовую выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "23c7cf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data['lemm'], data['toxic'], test_size=.2, random_state = 12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "93556fa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127433 31859\n"
     ]
    }
   ],
   "source": [
    "print(len(X_train), len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815aa756",
   "metadata": {},
   "source": [
    "Создаем векторизацию обучающих и тестовых признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50f99b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "X_train_TFIDF = vectorizer.fit_transform(X_train)\n",
    "X_test_TFIDF = vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f873663",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<127433x134516 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 3357295 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "12079b5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('float64')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_TFIDF.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "95507c56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(127433, 134516) (31859, 134516)\n"
     ]
    }
   ],
   "source": [
    "print(X_train_TFIDF.shape, X_test_TFIDF.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1975093b",
   "metadata": {},
   "source": [
    "Поскольку в ходе проекта реализовывается задача классификации, то следует рассмотреть существующий баланс классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3fb86c59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.898388\n",
      "1    0.101612\n",
      "Name: toxic, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD1CAYAAABA+A6aAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAKgUlEQVR4nO3dX4id+V3H8fenCVGwtRdmLJo/nUCzaPwDlSEVemGhK2ZbSC4USUBQWZqriNIiRpRF4k1rQa8iGFCUgo2xFzK40Qh1i6BuzSytC0lIHeK2SbzodF0LIppGv17MqZ6eneQ82X0yZ+eb9wsC5/k9P875EoY3T55zziRVhSRp53vbogeQJI3DoEtSEwZdkpow6JLUhEGXpCYMuiQ1sXtRL7x3795aXl5e1MtL0o700ksvfa2qlrY6t7CgLy8vs7a2tqiXl6QdKcmXH3TOWy6S1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkppY2BeLdorls88veoRWXvn4hxc9gtSWV+iS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgYFPcmxJDeTrCc5u8X5g0leSPKFJC8n+dD4o0qSHmZu0JPsAs4DzwBHgFNJjsxs+3XgUlW9FzgJ/O7Yg0qSHm7IFfpRYL2qblXVPeAicGJmTwHfOXn8TuBfxhtRkjTE7gF79gG3p47vAO+b2fMbwF8l+QXgO4CnR5lOkjTYWG+KngL+sKr2Ax8CPpXkdc+d5HSStSRrGxsbI720JAmGBf0ucGDqeP9kbdqzwCWAqvp74NuBvbNPVFUXqmqlqlaWlpbe2MSSpC0NCfpV4HCSQ0n2sPmm5+rMnq8AHwRI8v1sBt1LcEnaRnODXlX3gTPAFeAGm59muZbkXJLjk20fAz6S5B+BTwM/V1X1uIaWJL3ekDdFqarLwOWZteemHl8H3j/uaJKkR+E3RSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpoYFPQkx5LcTLKe5OwD9vx0kutJriX543HHlCTNs3vehiS7gPPAjwN3gKtJVqvq+tSew8CvAu+vqteSfPfjGliStLUhV+hHgfWqulVV94CLwImZPR8BzlfVawBV9dVxx5QkzTMk6PuA21PHdyZr054Cnkryt0leTHJsrAElScPMveXyCM9zGPgAsB/4myQ/VFX/Nr0pyWngNMDBgwdHemlJEgy7Qr8LHJg63j9Zm3YHWK2qb1TVPwNfYjPw36KqLlTVSlWtLC0tvdGZJUlbGBL0q8DhJIeS7AFOAqsze/6Mzatzkuxl8xbMrfHGlCTNMzfoVXUfOANcAW4Al6rqWpJzSY5Ptl0BXk1yHXgB+OWqevVxDS1Jer1B99Cr6jJweWbtuanHBXx08keStAB+U1SSmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJamJQUFPcizJzSTrSc4+ZN9PJqkkK+ONKEkaYm7Qk+wCzgPPAEeAU0mObLHvHcAvAp8fe0hJ0nxDrtCPAutVdauq7gEXgRNb7PtN4BPAf444nyRpoCFB3wfcnjq+M1n7P0l+BDhQVc+POJsk6RG86TdFk7wN+G3gYwP2nk6ylmRtY2Pjzb60JGnKkKDfBQ5MHe+frH3TO4AfBD6X5BXgR4HVrd4YraoLVbVSVStLS0tvfGpJ0usMCfpV4HCSQ0n2ACeB1W+erKqvV9XeqlquqmXgReB4Va09loklSVuaG/Squg+cAa4AN4BLVXUtybkkxx/3gJKkYXYP2VRVl4HLM2vPPWDvB978WJKkR+U3RSWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhMGXZKaMOiS1IRBl6QmDLokNWHQJakJgy5JTRh0SWrCoEtSEwZdkpow6JLUxKCgJzmW5GaS9SRntzj/0STXk7yc5LNJ3j3+qJKkh5kb9CS7gPPAM8AR4FSSIzPbvgCsVNUPA58BfmvsQSVJDzfkCv0osF5Vt6rqHnARODG9oapeqKr/mBy+COwfd0xJ0jxDgr4PuD11fGey9iDPAn+x1Ykkp5OsJVnb2NgYPqUkaa5R3xRN8jPACvDJrc5X1YWqWqmqlaWlpTFfWpKeeLsH7LkLHJg63j9Z+xZJngZ+DfixqvqvccaTJA015Ar9KnA4yaEke4CTwOr0hiTvBX4POF5VXx1/TEnSPHODXlX3gTPAFeAGcKmqriU5l+T4ZNsngbcDf5rki0lWH/B0kqTHZMgtF6rqMnB5Zu25qcdPjzyXJOkR+U1RSWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqYtD/WCTprWf57POLHqGVVz7+4UWP8KZ5hS5JTRh0SWrCoEtSEwZdkpow6JLUhEGXpCYMuiQ1YdAlqQmDLklNGHRJasKgS1ITBl2SmjDoktSEQZekJgy6JDVh0CWpCYMuSU0YdElqwqBLUhODgp7kWJKbSdaTnN3i/Lcl+ZPJ+c8nWR59UknSQ80NepJdwHngGeAIcCrJkZltzwKvVdV7gN8BPjH2oJKkhxtyhX4UWK+qW1V1D7gInJjZcwL4o8njzwAfTJLxxpQkzbN7wJ59wO2p4zvA+x60p6ruJ/k68F3A16Y3JTkNnJ4c/nuSm29kaG1pLzN/329F8d9uTyJ/Nsf17gedGBL00VTVBeDCdr7mkyLJWlWtLHoOaZY/m9tnyC2Xu8CBqeP9k7Ut9yTZDbwTeHWMASVJwwwJ+lXgcJJDSfYAJ4HVmT2rwM9OHv8U8NdVVeONKUmaZ+4tl8k98TPAFWAX8AdVdS3JOWCtqlaB3wc+lWQd+Fc2o6/t5a0svVX5s7lN4oW0JPXgN0UlqQmDLklNGHRJamJbP4eucST5Pja/nbtvsnQXWK2qG4ubStKieYW+wyT5FTZ//UKAf5j8CfDprX5xmvRWkeTnFz1Dd37KZYdJ8iXgB6rqGzPre4BrVXV4MZNJD5fkK1V1cNFzdOYtl53nf4DvBb48s/49k3PSwiR5+UGngHdt5yxPIoO+8/wS8Nkk/8T//9K0g8B7gDOLGkqaeBfwE8BrM+sB/m77x3myGPQdpqr+MslTbP5a4+k3Ra9W1X8vbjIJgD8H3l5VX5w9keRz2z7NE8Z76JLUhJ9ykaQmDLokNWHQJakJgy5JTRh0SWrifwHS0Rab3rKGXwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_frequency = data['toxic'].value_counts(normalize= True)\n",
    "print(class_frequency)\n",
    "class_frequency.plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30616596",
   "metadata": {},
   "source": [
    "Наблюдается явный дисбаланс классов, однако, в дальнейшем я не буду реализовывать балансировку классов, поскольку так можно искусственно завысить качество модели, что может сбить с толку и тогда к заказчику отправится не лучшая модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d83f337",
   "metadata": {},
   "source": [
    "На следующем этапе я обучу несколько моделей классификаторов - LogisticRegression(), RandomForestClassifier() и DecisionTreeClassifier(). Раннее я также обучила GradientBoostingClassifier(), однако модель продемонстрировала худшие результаты среди всех моделей - f1 = 0.6 при выборке n=80000, а также со временем обучения и кроссвалидации более часа без подбора гиперпараметров (подбор гиперпараметров шел более 7 часов). Поэтому, чтобы не тратить временные и энергетические ресурсы меня и заказчика, было принято решение ограничиться тремя моделями классификаторами."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12370e4",
   "metadata": {},
   "source": [
    "Для начала следует обучить модели без подбора гиперпараметров и оценить с помощью кроссвалидации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c8bc8a19",
   "metadata": {},
   "outputs": [],
   "source": [
    "regressors = [\n",
    "    RandomForestClassifier(random_state = 12345),\n",
    "    DecisionTreeClassifier(random_state = 12345),\n",
    "    LogisticRegression()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91a678b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(random_state=12345)\n",
      "\tВремя обучения: 550.438s\n",
      "\tВремя предсказания+оценка: 4677.484s\n",
      "Средняя оценка качества модели: 0.6854021999078822\n",
      "\n",
      "DecisionTreeClassifier(random_state=12345)\n",
      "\tВремя обучения: 332.460s\n",
      "\tВремя предсказания+оценка: 1304.955s\n",
      "Средняя оценка качества модели: 0.7162266027486311\n",
      "\n",
      "LogisticRegression()\n",
      "\tВремя обучения: 45.153s\n",
      "\tВремя предсказания+оценка: 223.086s\n",
      "Средняя оценка качества модели: 0.7226394868769386\n",
      "\n"
     ]
    }
   ],
   "source": [
    "head = 10\n",
    "for model in regressors[:head]:\n",
    "    start = time()\n",
    "    model.fit(X_train_TFIDF, y_train)\n",
    "    train_time = time() - start\n",
    "    start = time()\n",
    "    pred_train = model.predict(X_train_TFIDF)\n",
    "    scores = cross_val_score(estimator = model, X=X_train_TFIDF, y=y_train, scoring='f1')\n",
    "    final_score = sum(scores) / len(scores)\n",
    "    predict_time = time()-start\n",
    "    print(model)\n",
    "    print(\"\\tВремя обучения: %0.3fs\" % train_time)\n",
    "    print(\"\\tВремя предсказания+оценка: %0.3fs\" % predict_time)\n",
    "    print('Средняя оценка качества модели:', final_score)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f80c78",
   "metadata": {},
   "source": [
    "Ни одна из моделей не удовлетворяет условию заказчика, чтобы f1 была больше 0,75. Однако, следует проверить, не изменится ли ситуация после подбора оптимальных гиперпараметров (и ещё раз оценить логистическую регрессию). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "84bccd8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_1 = {'max_depth' : (range(1, 7))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "407baa21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 6} \n",
      "\n",
      "0.5375296524240547 \n",
      "\n",
      "CPU times: user 14min 3s, sys: 534 ms, total: 14min 3s\n",
      "Wall time: 14min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid = GridSearchCV(DecisionTreeClassifier(),parameters_1, scoring='f1', cv = 10)\n",
    "\n",
    "model = grid.fit(X_train_TFIDF, y_train)\n",
    "\n",
    "print(model.best_params_,'\\n')\n",
    "print(model.best_score_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7e6e7015",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_2 = {'n_estimators' : (range(10, 100, 10)),\n",
    "              'max_depth' : (range(1, 7))\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "aca713e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 1, 'n_estimators': 10} \n",
      "\n",
      "0.0 \n",
      "\n",
      "CPU times: user 47min 43s, sys: 3.39 s, total: 47min 46s\n",
      "Wall time: 47min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid = GridSearchCV(RandomForestClassifier(),parameters_2, scoring='f1', cv = 10)\n",
    "\n",
    "model = grid.fit(X_train_TFIDF, y_train)\n",
    "\n",
    "print(model.best_params_,'\\n')\n",
    "print(model.best_score_,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "95ec0cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.9 s, sys: 26.8 s, total: 46.7 s\n",
      "Wall time: 46.7 s\n"
     ]
    }
   ],
   "source": [
    "%time clf = LogisticRegression(random_state=43).fit(X_train_TFIDF, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ee66bb4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = cross_val_score(estimator = clf, X=X_train_TFIDF, y=y_train, scoring='f1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "715b59e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7226394868769386"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_score = sum(score) / len(score)\n",
    "final_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf9ae78e",
   "metadata": {},
   "source": [
    "Таким образом, качество моделей DecisionTreeClassifier() и RandomForestClassifier() не повысилось несмотря на подбор гиперпараметром (возможно, в случае DecisionTreeClassifier() было слишком ограничено количество подбираемых ги перпараметров, олнако, следует помнить о специфике составлющих успешности кода в рамках данного проекта - это не только качество, но и время)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfc16dbb",
   "metadata": {},
   "source": [
    "Лучшей моделью оказалась модель LogisticRegression(), а также оптимальная по времени обучения. Ее следует протестировать на тестовой выборке."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb02f5e-8788-4cf6-a2b3-da1f09f77659",
   "metadata": {},
   "source": [
    "# Тестирование лучшей модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "26d53150",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7493520918178451\n",
      "CPU times: user 21.4 s, sys: 25.5 s, total: 46.9 s\n",
      "Wall time: 47 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model_1 = LogisticRegression(random_state=43)\n",
    "model_1.fit(X_train_TFIDF, y_train)\n",
    "predict_valid = model_1.predict(X_test_TFIDF)\n",
    "print(f1_score(predict_valid, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c738e7",
   "metadata": {},
   "source": [
    "**Финальный вывод:**  \n",
    "\n",
    "- Была проведена очистка текста от стоп-слов;\n",
    "- Была проведена лемматизация текста;  \n",
    "- Были приведены в порядок признаки, чтобы избежать утечки;\n",
    "- Поскольку задачей проекта является предсказание класса комментария, то для этой задачи были обучены регрессионные модели RandomForestClassifier(), DecisionTreeClassifier() и LogisticRegression();\n",
    "- Из этих моделей удовлетворяла условиям заказчика о допустимом пороге f1 только LogisticRegression(), которая и оказалась лучшей моделью и именно она была протестирована на тестовой выборке; \n",
    "- Модель LogisticRegression() на тестовой выборке так же удовлетворяет требованиям заказчика, а именно f1 = 0.750694058856191"
   ]
  }
 ],
 "metadata": {
  "ExecuteTimeLog": [
   {
    "duration": 2533,
    "start_time": "2023-07-13T10:32:11.679Z"
   },
   {
    "duration": 5007,
    "start_time": "2023-07-13T10:33:09.942Z"
   },
   {
    "duration": 23243,
    "start_time": "2023-07-13T10:33:17.842Z"
   },
   {
    "duration": 2593,
    "start_time": "2023-07-13T10:34:30.817Z"
   },
   {
    "duration": 3828,
    "start_time": "2023-07-13T10:34:36.710Z"
   },
   {
    "duration": 13608,
    "start_time": "2023-07-13T10:34:59.467Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-13T10:36:54.140Z"
   },
   {
    "duration": 3205,
    "start_time": "2023-07-13T10:37:02.118Z"
   },
   {
    "duration": 58,
    "start_time": "2023-07-13T10:37:16.382Z"
   },
   {
    "duration": 23,
    "start_time": "2023-07-13T10:37:22.442Z"
   },
   {
    "duration": 29,
    "start_time": "2023-07-13T10:37:32.633Z"
   },
   {
    "duration": 281,
    "start_time": "2023-07-13T10:37:35.421Z"
   },
   {
    "duration": 3747,
    "start_time": "2023-07-13T10:37:51.648Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-13T10:38:00.738Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-13T10:38:13.913Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-13T10:38:18.707Z"
   },
   {
    "duration": 7454,
    "start_time": "2023-07-13T10:38:37.980Z"
   },
   {
    "duration": 15,
    "start_time": "2023-07-13T10:39:10.949Z"
   },
   {
    "duration": 68,
    "start_time": "2023-07-13T10:41:21.013Z"
   },
   {
    "duration": 767,
    "start_time": "2023-07-13T10:42:43.714Z"
   },
   {
    "duration": 3,
    "start_time": "2023-07-13T10:42:53.625Z"
   },
   {
    "duration": 25,
    "start_time": "2023-07-13T10:43:06.337Z"
   },
   {
    "duration": 893326,
    "start_time": "2023-07-13T10:43:45.136Z"
   },
   {
    "duration": 13,
    "start_time": "2023-07-13T11:00:05.210Z"
   },
   {
    "duration": 65,
    "start_time": "2023-07-13T11:00:32.838Z"
   },
   {
    "duration": 56,
    "start_time": "2023-07-13T11:01:44.017Z"
   },
   {
    "duration": 59,
    "start_time": "2023-07-13T11:01:58.405Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-13T11:02:04.721Z"
   },
   {
    "duration": 5896,
    "start_time": "2023-07-13T11:02:14.577Z"
   },
   {
    "duration": 4,
    "start_time": "2023-07-13T11:02:25.879Z"
   },
   {
    "duration": 355,
    "start_time": "2023-07-13T11:11:42.122Z"
   },
   {
    "duration": 139,
    "start_time": "2023-07-13T11:11:48.262Z"
   },
   {
    "duration": 6,
    "start_time": "2023-07-13T11:12:04.460Z"
   },
   {
    "duration": 51907,
    "start_time": "2023-07-13T11:13:37.449Z"
   },
   {
    "duration": 250592,
    "start_time": "2023-07-13T11:14:29.360Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-13T11:19:48.961Z"
   },
   {
    "duration": 5,
    "start_time": "2023-07-13T11:20:36.659Z"
   },
   {
    "duration": 50926,
    "start_time": "2023-07-13T11:21:41.729Z"
   },
   {
    "duration": 57,
    "start_time": "2023-11-02T10:43:42.729Z"
   },
   {
    "duration": 1942,
    "start_time": "2023-11-02T10:43:49.530Z"
   },
   {
    "duration": 3647,
    "start_time": "2023-11-02T10:43:51.474Z"
   },
   {
    "duration": 14456,
    "start_time": "2023-11-02T10:43:55.123Z"
   },
   {
    "duration": 5682,
    "start_time": "2023-11-02T10:44:09.581Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-02T10:44:15.265Z"
   },
   {
    "duration": 2366,
    "start_time": "2023-11-02T10:44:15.269Z"
   },
   {
    "duration": 34,
    "start_time": "2023-11-02T10:44:17.637Z"
   },
   {
    "duration": 12,
    "start_time": "2023-11-02T10:44:17.672Z"
   },
   {
    "duration": 11,
    "start_time": "2023-11-02T10:44:17.685Z"
   },
   {
    "duration": 214,
    "start_time": "2023-11-02T10:44:17.708Z"
   },
   {
    "duration": 839,
    "start_time": "2023-11-02T10:44:17.923Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-02T10:44:18.764Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-02T10:44:18.770Z"
   },
   {
    "duration": 7,
    "start_time": "2023-11-02T10:44:18.785Z"
   },
   {
    "duration": 5600,
    "start_time": "2023-11-02T10:44:18.793Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-02T10:44:24.395Z"
   },
   {
    "duration": 46,
    "start_time": "2023-11-02T10:44:24.407Z"
   },
   {
    "duration": 622,
    "start_time": "2023-11-02T10:44:24.454Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-02T10:44:25.077Z"
   },
   {
    "duration": 31,
    "start_time": "2023-11-02T10:44:25.083Z"
   },
   {
    "duration": 690426,
    "start_time": "2023-11-02T10:44:25.115Z"
   },
   {
    "duration": 7,
    "start_time": "2023-11-02T10:55:55.543Z"
   },
   {
    "duration": 248,
    "start_time": "2023-11-02T10:55:55.552Z"
   },
   {
    "duration": 157,
    "start_time": "2023-11-02T10:55:55.802Z"
   },
   {
    "duration": 36,
    "start_time": "2023-11-02T10:55:55.961Z"
   },
   {
    "duration": 71,
    "start_time": "2023-11-02T10:55:55.999Z"
   },
   {
    "duration": 4806,
    "start_time": "2023-11-02T10:55:56.072Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-02T11:47:01.246Z"
   },
   {
    "duration": 1876,
    "start_time": "2023-11-03T02:33:50.336Z"
   },
   {
    "duration": 3936,
    "start_time": "2023-11-03T02:33:52.215Z"
   },
   {
    "duration": 10801,
    "start_time": "2023-11-03T02:33:56.153Z"
   },
   {
    "duration": 5962,
    "start_time": "2023-11-03T02:34:06.956Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-03T02:34:12.920Z"
   },
   {
    "duration": 2661,
    "start_time": "2023-11-03T02:34:12.925Z"
   },
   {
    "duration": 40,
    "start_time": "2023-11-03T02:34:15.588Z"
   },
   {
    "duration": 62,
    "start_time": "2023-11-03T02:34:15.630Z"
   },
   {
    "duration": 76,
    "start_time": "2023-11-03T02:34:15.694Z"
   },
   {
    "duration": 248,
    "start_time": "2023-11-03T02:34:15.772Z"
   },
   {
    "duration": 940,
    "start_time": "2023-11-03T02:34:16.022Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-03T02:34:16.964Z"
   },
   {
    "duration": 14,
    "start_time": "2023-11-03T02:34:16.968Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-03T02:34:16.985Z"
   },
   {
    "duration": 6199,
    "start_time": "2023-11-03T02:34:16.991Z"
   },
   {
    "duration": 16,
    "start_time": "2023-11-03T02:34:23.191Z"
   },
   {
    "duration": 47,
    "start_time": "2023-11-03T02:34:23.209Z"
   },
   {
    "duration": 701,
    "start_time": "2023-11-03T02:34:23.258Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-03T02:34:23.961Z"
   },
   {
    "duration": 19,
    "start_time": "2023-11-03T02:34:23.966Z"
   },
   {
    "duration": 726656,
    "start_time": "2023-11-03T02:34:23.987Z"
   },
   {
    "duration": 8,
    "start_time": "2023-11-03T02:46:30.645Z"
   },
   {
    "duration": 103,
    "start_time": "2023-11-03T02:46:30.655Z"
   },
   {
    "duration": 58,
    "start_time": "2023-11-03T02:46:30.760Z"
   },
   {
    "duration": 31,
    "start_time": "2023-11-03T02:46:30.820Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-03T02:46:30.853Z"
   },
   {
    "duration": 4971,
    "start_time": "2023-11-03T02:46:30.858Z"
   },
   {
    "duration": 4,
    "start_time": "2023-11-03T02:46:35.831Z"
   },
   {
    "duration": 124,
    "start_time": "2023-11-03T02:46:35.836Z"
   },
   {
    "duration": 32,
    "start_time": "2023-11-03T02:46:35.962Z"
   },
   {
    "duration": 182,
    "start_time": "2023-11-03T02:46:35.996Z"
   },
   {
    "duration": 3,
    "start_time": "2023-11-03T02:46:36.180Z"
   },
   {
    "duration": 7133636,
    "start_time": "2023-11-03T02:46:36.184Z"
   },
   {
    "duration": 76,
    "start_time": "2023-11-03T04:45:29.824Z"
   },
   {
    "duration": 844299,
    "start_time": "2023-11-03T04:45:29.905Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-03T04:59:34.215Z"
   },
   {
    "duration": 2868296,
    "start_time": "2023-11-03T04:59:34.224Z"
   },
   {
    "duration": 46702,
    "start_time": "2023-11-03T05:47:22.522Z"
   },
   {
    "duration": 230692,
    "start_time": "2023-11-03T05:48:09.227Z"
   },
   {
    "duration": 6,
    "start_time": "2023-11-03T05:51:59.922Z"
   },
   {
    "duration": 46986,
    "start_time": "2023-11-03T05:51:59.933Z"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
